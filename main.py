# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UV7Ysbi-kKoZeOSU3-RYJeRGnASKfZQN
"""

import re
import numpy as np
from pathlib import Path
from sklearn.cluster import SpectralClustering, AgglomerativeClustering, DBSCAN
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA
from sklearn.metrics import adjusted_rand_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
import matplotlib.pyplot as plt

FIXED_POS_TAGS = [
    'adp', 'adv', 'aux', 'cconj', 'noun',
    'num', 'part', 'pron', 'propn', 'sconj',
    'verb', 'intj', 'sym'
]
n = len(FIXED_POS_TAGS)
pos_to_idx = {pos: i for i, pos in enumerate(FIXED_POS_TAGS)}

def segment_motifs(tag_sequence):
    motifs = []
    S = set()
    for p in tag_sequence:
        if p not in pos_to_idx: continue
        idx = pos_to_idx[p]
        if idx in S:
            motifs.append(S.copy())
            S = {idx}
        else:
            S.add(idx)
    if S: motifs.append(S)
    return motifs

def encode_motif(S):
    v = np.zeros(n, dtype=int)
    for i in S: v[i] = 1
    return v

def phi_document(tokens):
    tags = [m.group() for tok in tokens if (m := re.search(r'[a-zA-Z]+$', tok))]
    motifs = segment_motifs(tags)
    k = len(motifs)
    M_doc = np.zeros((n, n), dtype=float)
    if k > 0:
        for S in motifs:
            v = encode_motif(S)
            M_doc += np.outer(v, v)
        M_doc /= k
    tri = np.triu_indices(n)
    return M_doc[tri].flatten()

def segment_first_order_motifs(tag_sequence):
    return [{pos_to_idx[p]} for p in tag_sequence if p in pos_to_idx]

def phi_first_order_document(tokens):
    tags = [m.group() for tok in tokens if (m := re.search(r'[a-zA-Z]+$', tok))]
    motifs = segment_first_order_motifs(tags)
    v_sum = np.zeros(n, dtype=int)
    for S in motifs:
        v_sum += encode_motif(S)
    return v_sum

def feature_extractor(method):
    if method == 'original':
        return lambda tokens: phi_document(tokens)
    elif method == 'first_order':
        return lambda tokens: phi_first_order_document(tokens)
    elif method == 'bow':
        vectorizer = CountVectorizer()
        return lambda docs: vectorizer.fit_transform(docs).toarray()
    elif method == 'tfidf':
        vectorizer = TfidfVectorizer()
        return lambda docs: vectorizer.fit_transform(docs).toarray()
    elif method == 'ngrams':
        vectorizer = TfidfVectorizer(ngram_range=(2, 2))
        return lambda docs: vectorizer.fit_transform(docs).toarray()
    else:
        raise ValueError("Unsupported feature method")

def main():
    BASE_DIRS = [
        Path('corpus1'),
        Path('corpus2')
    ]
    files = []
    for d in BASE_DIRS:
        files.extend(sorted(d.glob('*.txt')))

    label_map = {
        'Analects': 0, 'Book of Rites': 0, 'Mencius': 0,
        'Spring and Autumn and Warring States': 1, 'Tang':1, 'Western Zhou': 1,'Eastern Zhou': 1,
        'Diamond Sutra': 2, 'Heart Sutra': 2,
        'Verses of Chu': 3
    }

    true_labels = [label_map[fp.stem] for fp in files]
    y_true = np.array(true_labels)

    token_list = [fp.read_text(encoding='utf-8').split() for fp in files]
    tag_docs = [' '.join([m.group() for tok in tokens if (m := re.search(r'[a-zA-Z]+$', tok))])
                for tokens in token_list]

    methods = [
        ('Original Motif', 'original', token_list),
    ]

    cluster_config = {
        'GaussianMixture': GaussianMixture(
            n_components=4,
            random_state=42
        )
    }

    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Arial'],
        'axes.labelsize': 12,
        'xtick.labelsize': 10,
        'ytick.labelsize': 10,
        'legend.fontsize': 10,
        'figure.titlesize': 14,
        'savefig.dpi': 300,
        'savefig.format': 'png'
    })

    output_dir = Path("cluster_visualizations")
    output_dir.mkdir(exist_ok=True)

    for method_name, method_key, data in methods:
        if method_key in ['original', 'first_order']:
            X = np.vstack([feature_extractor(method_key)(tokens) for tokens in data])
        else:
            X = feature_extractor(method_key)(data)

        if method_key in ['original', 'first_order']:
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
        else:
            X_scaled = X

        for cluster_name, clustering in cluster_config.items():
            if isinstance(clustering, GaussianMixture):
                y_pred = clustering.fit(X_scaled).predict(X_scaled)
            else:
                y_pred = clustering.fit_predict(X_scaled)

            ari = adjusted_rand_score(y_true, y_pred)

            coords = PCA(n_components=2).fit_transform(X_scaled)
            plt.figure(figsize=(8, 6))

            colors = ['#1f77b4', '#2ca02c', '#d62728', '#9467bd']
            cluster_labels = {
                0: 'Literature',
                1: 'Classics',
                2: 'Philosophy',
                3: 'History'
            }

            for c, color in zip(np.unique(y_pred), colors):
                idx = np.where(y_pred == c)
                plt.scatter(
                    coords[idx, 0], coords[idx, 1],
                    label=f'{cluster_labels.get(c, "Unknown")}',
                    alpha=0.7,
                    edgecolors='white',
                    s=60,
                    color=color
                )

            for i, fp in enumerate(files):
                plt.text(
                    coords[i, 0] + 0.03, coords[i, 1] + 0.03,
                    fp.stem,
                    fontsize=6,
                    ha='left',
                    va='bottom',
                    alpha=0.8,
                    bbox=dict(facecolor='white', alpha=0.5, edgecolor='none')
                )

            plt.xlabel('', fontweight='bold')
            plt.ylabel('', fontweight='bold')
            plt.title(f'', pad=20)

            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')

            plt.grid(alpha=0.3, linestyle='--', linewidth=0.8)

            filename = output_dir / f"{method_name.replace(' ', '_')}_{cluster_name}_ARI_{ari:.4f}.png"
            plt.savefig(filename, bbox_inches='tight', dpi=300)

            plt.show()

if __name__ == '__main__':
    main()